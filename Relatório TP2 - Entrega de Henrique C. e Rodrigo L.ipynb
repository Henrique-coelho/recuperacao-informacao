{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho Prático 2: Indexador\n",
    "### Relatório de Henrique Coelho e Rodrigo Lopes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Primeiramente, damos entrada neste trecho comentando sobre a experiência desenvolvendo desta atividade. Esta parte da atividade teve grandes bloqueio na produção do strucutre.py, e facilidade no desenvolvimento do indexer.py. Ademais, houve uma dificuldade quanto o desenvolvimento da atividade final, visto a grande necessidade de memória necessária para sua execução.\n",
    "\n",
    "    Um dos grandes desafios desta atividade foi a compreensão do funcionamento do FileIndex e sua sincrônia entre os objetos de TermFilePosition e o dados registrados nos arquivos. Muito desta parte nos bloqueou quanto ao progresso nas atividades 8 e 9, estas que por um tempo prolongado criava arquivo com dados nulos e imutáveis, retornando objetos sem valores para term_file_start_pos e doc_count_with_term. Posteriormente, este obstáculo nos postergou ainda mais posteriormente na atividade 15, onde percebemos que a persistência do erro desta natureza nos trouxe resultados corretos pelo teste apesar dos objetos de TermFilePosition no dic_index estavam incorretos. \n",
    "    \n",
    "    Depois de muitas tentativas, a resolução envolvel a reescrita completa do modelo desenvolvido anteriormente, o que envolveu também a recriação da classe mãe Index, que apesar de ter suas partes funcionais para a subclasse HashIndex, foi necessário a refatoração para a outra subclasses. Alguns outros bloqueios encontrados no desenvolvimento deste projeto se tratam de alguns modelos testes para atividade 4 ou 5 que esperavam dados incorretos com resposta (pretendemos commitar uma correção para este erro depois no git geral da disciplina), que nos ocupou por algumas sessões de execução. \n",
    "\n",
    "    Ademais, foi encontrado um problema que muitos outros grupo não tiveram a experiência, visto que esta origem era de conflito entre Linux vs Windows. Quando abrindo documentos do tipo html no Linux, aparentemente se utiliza a formatação correta, porém o Windows força um tipo de formatação não ideal para palavras portuguesas. Assim, foi forçado o tipo de codificação \"utf-8\" quando lendo estes tipos de arquivos (observação: não temos certeza se este é o método correto, sabemos que este foi o sucesso para a atividade 15, não temos certeza quanto a atividade 16)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Discussão sobre a decisão de implementação adotada:  Quais foram os principais desafios e soluções? Qual é a vantagem/desvantagem das suas soluções sob as outras alternativas (por exemplo, uso do índice em memória principal x ocorrência de termos em memória secundária)? O que você melhoraria  no seu código para diminuir o consumo de memoria ou deixá-lo mais eficiente?\n",
    "\n",
    "    Quanto a decisão de um melhor indexador, foi possível observar que o mais rápido seria o HashIndex, que foi capaz de apresentar resultados em torno de 1 hora, até o processamento do VSCode ceder e este não conseguir executar mais. Já, o FileIndex executou por 3 horas, podendo adquirir até em torno de 7% do total de pastas visitadas. Apesar de não ter sucesso a tempo para esta atividade, foi possível inferir alguns detalhes. Primeiramente, o HashIndex pesa muito a memória RAM do código em processamento, sendo muito inviável em máquinas pequenas. Caso o poder de processaento fosse potente para outras máquinas, esta escolha seria muito interessante visto que outros grupos informaram um tempo de em torno de 20 minutos, o que indica resultados bem mais rápidos em máquina potentes. Já o FileIndex consegue trazer permanencia as requisições, armazená-las em memória para uso futuros, o que pode ser interessante em alguns cenários de páginas constantemente utilizadas. Ademais, com o auxílio do TermFilePosition, o FileIndex é capaz de armazenar o seus dados de uma forma muito eficiente e compacta, ainda permitindo detalhamento sobre as palavras e suas origens. Isto torna o uso do FileIndex poderoso e talvez mais interessante em aplicações de larga escala. Quanto a melhorias, seria interessante realizar o método finish_indexing para ao final da leitura de todo o processo invés de todo o arquivo, visto que o caso atual requer a execução deste sistema todo arquivo html. Isto se trata de entorno de 10000 execução a mais na atividade 16, um processo custoso que poderia ser amenizado."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quais são as bibliotecas externas utilizadas? Explique o funcionamento da técnica de stemming adotada.\n",
    "\n",
    "    O BeautifulSoup é uma ferramenta essencial para a leitura de arquivos HTML, e o SnowballerStemmer é essencial para o processo de stemming. Esta biblioteca realiza todo os processo de realização de stemming de uma palavra, que seria a tokenização destas, a remoção de sufixos, a redução à radicais e a normalização destas palavras. Os tokens resultantes são então propagados para as etapas seguintes do sistema, removendo stopwords e caracteres indevidos. Assim então é indexados todos os valores."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Qual foi a estrutura do índice utilizado? Quanto MB de ram cada solução de índice gastou? Em quanto tempo foi realizado a indexação? Qual foi a média por documento?\n",
    "    Tivemos sucessos em execução em ambos modelos de FileIndex e HashIndex, possuímos mais sucesso utilizando o HashIndex para esta implementação. foi observado que utilizamos em torno de 560-610 MB por modelagem de cada índice, onde a média por documento foi em torno de 590MB. Em questão de tempo, é difícil determinar quanto de tempo foi utilizado por cada índice em tempo de execução. O melhor que conseguimos notar foi que cada novo conjunto de índice gastou um tempo maior que o anterior, uma vez que o sistema envolveu a inclusão de dados de índices anteriores ao criar o novo arquivo idx. Ao total, nossa execução gastou em torno de 20 minutos, ao contrário do FileIndex que gastou em torno de 1 hora."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Por conclusão desta atividade, acredita se ter resultados positivos, apesar destes não serem aprentados a tempo para esta entrega visto as limitações da máquinas envolvidas no processamento. O desenvolvimento das classes indexer e structure forem be sucedidas ao final, faltando apenas a execução em larga escala. Logo, esperamos finalizar estes resultados separadamentes, e prosseguir para a etapa seguinte. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
